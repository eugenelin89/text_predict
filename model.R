library(dplyr)




# input is ngram vector
learn_from_ngrams <- function(ngram){ 
  model <- list()
  for(i in 1: length(ngram)){
  #for(i in 1: 1000){
    rw <- ngram[i]
    str_vec <- strsplit(rw ,split=',', fixed=TRUE)[[1]] # e.g. [1] "99"   "at"   "the"  "time" "522"
    key <- paste(str_vec[2], str_vec[3], sep = " ")  #paste(rw$word1, rw$word2, sep = " ")
    val <- paste(rep(str_vec[4], strtoi(vec[5])), collapse = " ")  #paste(rep(rw$word3, rw$n), collapse = " ")
      
    cur_val <- model[[key]]
    if(is.null(cur_val)){
      # new entry
      model[key] = val
    }else{
      model[key] = paste(c(cur_val, val), collapse = " ")
    }

    if(i%%1000 == 0){
      print(i) # for visual inspection
    }

  }
  model
}



predict_next_word <- function(){
  
}

#bigrams <- readRDS("bigrams.rds")
#trigrams <- readRDS("trigrams.rds")
#ngrams_model <- learn_from_ngrams(bigrams, trigrams)
#next_word <- predict_next_word(ngrams_model, "thanks for")


trigrams <- readRDS("trigrams.rds") # Read trigrams.rds generated by eda.R into dataframe
write.csv(trigrams, file="trigrams.csv", quote=FALSE) # Write trigrams dataframe to CSV
sample_text("trigrams.csv", "trigrams_sample.csv") # Sampling of trigrams CSV (to .1)
trigrams_sample <- readLines("trigrams_sample.csv") # Read sample into vector
my_mod <- learn_from_ngrams(trigrams_sample) # from sample vector, learn the model, which is just a List.
save(my_mod, file="trigrams_model.RData") # save the trigram model to disk
load("trigrams_model.RData") # load trigram model